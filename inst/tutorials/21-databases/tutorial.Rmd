---
title: Databases
author: David Kane
tutorial:
  id: databases
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Tutorial for Chapter 21: Databases'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)

library(DBI)
library(dbplyr)
library(tidyverse)
library(duckdb)
library(nycflights13)

# library(RSQLite)
# library(RPostgres)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

my_sql <- "
  SELECT carat, cut, clarity, color, price 
  FROM diamonds 
  WHERE price > 15000
"

# Copying all the nycflights takes a long time. So, we only want to do it once,
# here. And then use that connection in the SQL basics section. (Really ought to
# figure out a way to delete this connection once the tutorial is over.) Also,
# need a way to warn students when the tutorial is knitting, and gets stuck at
# 1% for a minute or two, that there is nothing to worry about.

con_nyc <- DBI::dbConnect(duckdb::duckdb())
dbplyr::copy_nycflights13(con_nyc)
flights <- tbl(con_nyc, "flights")
planes <- tbl(con_nyc, "planes")

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Databases are tricky because nothing, including connection objects, last from one Exercise to another. So, we can either repeat code in every Exercise or we can set up a set of connection objects in the setup code chunk. We follow both approaches in different sections below. A good idea? -->

<!-- There is a lot of text in the first few questions. Maybe spread that out but adding a few help look up questions? -->


## Introduction
### 

*This is a ROUGH, UNFINISHED, draft.*

This tutorial covers [Chapter 21: Databases](https://r4ds.hadley.nz/databases.html) from [*R for Data Science (2e)*](https://r4ds.hadley.nz/) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. You will learn how to use [**DBI**](https://dbi.r-dbi.org/) and the [**dbplyr**](https://dbplyr.tidyverse.org/) packages to connect to databases and execute SQL.

## Database basics
### 

In this tutorial, you’ll first learn the basics of the **DBI** package: how to use it to connect to a database and then retrieve data with a SQL query. **SQL**, short for **s**tructured **q**uery **l**anguage, is the *lingua franca* of databases, and is an important language for all data scientists to learn. That said, we’re not going to start with SQL, but instead we’ll teach you the **dbplyr** package, which can translate your dplyr code to the SQL. We’ll use that as a way to teach you some of the most important features of SQL. 

### Exercise 1

Run `library()` for the [**DBI**](https://dbi.r-dbi.org/) package.

```{r database-basics-1, exercise = TRUE}

```

```{r database-basics-1-hint-1, eval = FALSE}
library(...)
```

```{r database-basics-1-test, include = FALSE}
library(DBI)
```

### 

At the simplest level, you can think about a database as a collection of data frames, called tables in database terminology. Like a data frame, a database table is a collection of named columns, where every value in the column is the same type. 

### Exercise 2

Run `library()` for the [**dbplyr**](https://dbplyr.tidyverse.org/) package.

```{r database-basics-2, exercise = TRUE}

```

```{r database-basics-2-hint-1, eval = FALSE}
library(...)
```

```{r database-basics-2-test, include = FALSE}
library(dbplyr)
```

### 

There are three high level differences between data frames and database tables:

* Database tables are stored on disk and can be arbitrarily large. Data frames are stored in memory, and are fundamentally limited (although that limit is still plenty large for many problems).

* Database tables almost always have indexes. Much like the index of a book, a database index makes it possible to quickly find rows of interest without having to look at every single row. Data frames and tibbles don’t have indexes, but data.tables (from the [**data.table**](https://rdatatable.gitlab.io/data.table/) package) do, which is one of the reasons that they’re so fast.

* Most classical databases are optimized for rapidly collecting data, not analyzing existing data. These databases are called row-oriented because the data is stored row-by-row, rather than column-by-column like R. More recently, there’s been much development of column-oriented databases that make analyzing the existing data much faster.

### Exercise 3

Run `library()` for the [**tidyverse**](https://tidyverse.tidyverse.org/) package.

```{r database-basics-3, exercise = TRUE}

```

```{r database-basics-3-hint-1, eval = FALSE}
...(tidyverse)
```

```{r database-basics-3-test, include = FALSE}
library(tidyverse)
```

### 

Databases are run by database management systems (DBMS’s for short), which come in three basic forms:

* Client-server DBMS’s run on a powerful central server, which you connect from your computer (the client). They are great for sharing data with multiple people in an organization. Popular client-server DBMS’s include PostgreSQL, MariaDB, SQL Server, and Oracle.

* Cloud DBMS’s, like Snowflake, Amazon’s RedShift, and Google’s BigQuery, are similar to client server DBMS’s, but they run in the cloud. This means that they can easily handle extremely large datasets and can automatically provide more compute resources as needed.

* In-process DBMS’s, like SQLite or duckdb, run entirely on your computer. They’re great for working with large datasets where you’re the primary user.

### Exercise 4

Run `library()` for the [**duckdb**](https://r.duckdb.org/) package.

```{r database-basics-4, exercise = TRUE}

```

```{r database-basics-4-hint-1, eval = FALSE}
...(duckdb)
```

```{r database-basics-4-test, include = FALSE}
library(duckdb)
```

### 

Setting up a client-server or cloud DBMS would be a pain for this book, so we’ll instead use an in-process DBMS that lives entirely in an R package: [**duckdb**](https://r.duckdb.org/). Thanks to the magic of DBI, the only difference between using **duckdb** and any other DBMS is how you’ll connect to the database. This makes it great to teach with because you can easily run this code as well as easily take what you learn and apply it elsewhere.

### Exercise 5

Run `library()` for the [**nycflights13**](https://nycflights13.tidyverse.org/) package.

```{r database-basics-5, exercise = TRUE}

```

```{r database-basics-5-hint-1, eval = FALSE}
...(nycflights13)
```

```{r database-basics-5-test, include = FALSE}
library(nycflights13)
```

### 

In this tutorial, we’ll introduce **DBI** and **dbplyr**. **DBI** is a low-level interface that connects to databases and executes SQL; **dbplyr** is a high-level interface that translates your **dplyr** code to SQL queries then executes them with **DBI**. We will use data from the **nycflights13** package.

## Connecting to a database
### 

To connect to the database from R, you’ll use a pair of packages:

You’ll always use DBI (database interface) because it provides a set of generic functions that connect to the database, upload data, run SQL queries, etc.

You’ll also use a package tailored for the DBMS you’re connecting to. This package translates the generic DBI commands into the specifics needed for a given DBMS. There’s usually one package for each DBMS, e.g. RPostgres for PostgreSQL and RMariaDB for MySQL.

### Exercise 1

You create a database connection using `dbConnect()`. The first argument selects the DBMS, then the second and subsequent arguments describe how to connect to it (i.e. where it lives and the credentials that you need to access it).

Run `dbConnect()` with the argument `duckdb()`.

```{r connecting-to-a-database-1, exercise = TRUE}

```

```{r connecting-to-a-database-1-hint-1, eval = FALSE}
dbConnect(...())
```

```{r connecting-to-a-database-1-test, include = FALSE}
# Need to close any connections you create, and it seems like the only way to do
# that (?) is to explicitly assign the connection to an object.

con <- dbConnect(duckdb())
dbDisconnect(con, shutdown=TRUE)
```

### 

If you can’t find a specific package for your DBMS, you can usually use the **odbc** package instead. This uses the ODBC protocol supported by many DBMS. **odbc** requires a little more setup because you’ll also need to install an ODBC driver and tell the **odbc** package where to find it.


### Exercise 2

Since we loaded the **DBI** and **duckdb** packages, we don't need to specify them using the `::` notation when we call `dbConnect` (which makes the connection) and `duckdb()` (which creates a temporary database). But, for safety, most of the time we do include the package name in these calls. So, copy the code from the previous question and replace `dbConnect` with `DBI::dbConnect` and `duckdb()` with `duckdb::duckdb()`.

```{r connecting-to-a-database-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r connecting-to-a-database-2-hint-1, eval = FALSE}
DBI::dbConnect(...::duckdb())
```

```{r connecting-to-a-database-2-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbDisconnect(con, shutdown=TRUE)
```

This might create warning message. Ignore it if so.

### 

The precise details of the connection vary a lot from DBMS to DBMS so unfortunately we can’t cover all the details here. This means you’ll need to do a little research on your own. Typically you can ask the other data scientists in your team or talk to your DBA (**d**ata**b**ase **a**dministrator). The initial setup will often take a little fiddling (and maybe some googling) to get it right, but you’ll generally only need to do it once.

### Exercise 3

Assign the result of the call to `DBI::dbConnect()` to an object named `con`. (There is nothing special about the name `con`, which stands for **con**nection. But using `con` to identify the connection object is fairly standard.)

```{r connecting-to-a-database-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r connecting-to-a-database-3-hint-1, eval = FALSE}
.. <- DBI::dbConnect(duckdb::duckdb())
```

```{r connecting-to-a-database-3-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbDisconnect(con, shutdown=TRUE)
```

### 

Connecting to duckdb is particularly simple because the defaults create a temporary database that is deleted when you quit R. That’s great for learning because it guarantees that you’ll start from a clean slate every time you restart R. 

But that it also a problem for a tutorial like this one because each Exercise is evaluated in isolation from everything else in the tutorial. That means we need to establish the connection in each Exercise. No worries though! We will provide the code for doing so, as needed.

### Exercise 4

If you want to use **duckdb** for a real data analysis project, you’ll also need to supply the dbdir argument to make a persistent database and tell `duckdb()` where to save it. Assuming you’re using an R project, it’s reasonable to store it in a duckdb directory for the current project.

To do so, add `dbdir = "duckdb"` as the second argument to your call to `dbConnect()`.

```{r connecting-to-a-database-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r connecting-to-a-database-4-hint-1, eval = FALSE}
con <- DBI::dbConnect(duckdb::duckdb(), ... = "duckdb")
```

```{r connecting-to-a-database-4-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = "duckdb")
dbDisconnect(con, shutdown=TRUE)
invisible(file.remove(c("duckdb", "duckdb.wal")))
```

### 

We won't use a permanent database for the rest of this tutorial.

duckdb is a high-performance database that’s designed very much for the needs of a data scientist. We use it here because it’s very easy to get started with, but it’s also capable of handling gigabytes of data with great speed.

### Exercise 5

Let's write the `mpg` data to the database we just created. Use `dbWriteTable()` and within it put the arguments `con`, `"mpg"`, and `ggplot2::mpg`. 

```{r connecting-to-a-database-5, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())

```

```{r connecting-to-a-database-5-hint-1, eval = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())

dbWriteTable(..., "mpg", ...)
```

```{r connecting-to-a-database-5-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "mpg", ggplot2::mpg)
dbDisconnect(con, shutdown=TRUE)
```

### 

When we use `dbWriteTable()` we need to supply three arguments: a database connection, the name of the table to create in the database, and a data frame of data.

### Exercise 6

Let's write the `diamonds` data to the database we just created. Use `dbWriteTable()` and within it put the arguments `con`, `"diamonds"`, and `ggplot2::diamonds`. 

```{r connecting-to-a-database-6, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())


```

```{r connecting-to-a-database-6-hint-1, eval = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
...(con, "...", ggplot2::diamonds)
```

```{r connecting-to-a-database-6-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
dbDisconnect(con, shutdown=TRUE)
```

### 

We use the packages tailored for the DBMS we’re connecting to. The **DBI** package translates the generic datbase commands into the specifics needed for a given DBMS. There’s usually one package for each **DBMS**, e.g. `RPostgres` for PostgreSQL and `RMariaDB` for MySQL.

### Exercise 7

You can check that the data is loaded correctly by using the `dbListTables()` function that lists all tables in the database. Run `dbListTables()` on `con`.

```{r connecting-to-a-database-7, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "mpg", ggplot2::mpg)
dbWriteTable(con, "diamonds", ggplot2::diamonds)


```

```{r connecting-to-a-database-7-hint-1, eval = FALSE}
...

dbListTables(...)
```

```{r connecting-to-a-database-7-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "mpg", ggplot2::mpg)
dbWriteTable(con, "diamonds", ggplot2::diamonds)
dbListTables(con)
dbDisconnect(con, shutdown=TRUE)
```

### 

If you’re using duckdb in a real project, we highly recommend learning about `duckdb_read_csv()` and `duckdb_register_arrow()`. These give you powerful and performant ways to quickly load data directly into duckdb, without having to first load it into R. 

Note that we will need to recreate the connection, and load any required data, for each new Exercise. But don't worry! We will supply the necessary code.

### Exercise 8

Let's use another DBI function: `dbReadTable()`. Start a pipe with `con` and use `dbReadTable()` with `"mpg"` as the only argument.

```{r connecting-to-a-database-8, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "mpg", ggplot2::mpg)


```

```{r connecting-to-a-database-8-hint-1, eval = FALSE}
...

con |>
  dbReadTable(...)
```

```{r connecting-to-a-database-8-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "mpg", ggplot2::mpg)

con |> 
  dbReadTable("mpg")

dbDisconnect(con, shutdown=TRUE)
```

### 

`dbReadTable()` returns a data frame, not a tibble. 

### Exercise 9

Start a pipe with `con` and use `dbReadTable()` with `"diamonds"` as the only argument. Continue the pipe with `as_tibble()`, thereby returning the data in a nice tibble format.

```{r connecting-to-a-database-9, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)


```

```{r connecting-to-a-database-9-hint-1, eval = FALSE}
...

con |> 
  dbReadTable("diamonds") |> 
  ...()
```

```{r connecting-to-a-database-9-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)

con |> 
  dbReadTable("diamonds") |> 
  as_tibble()

dbDisconnect(con, shutdown=TRUE)
```

### 

Connection requests often look more like these examples:

````
con <- DBI::dbConnect(
  RMariaDB::MariaDB(), 
  username = "foo"
)
con <- DBI::dbConnect(
  RPostgres::Postgres(), 
  hostname = "databases.mycompany.com", 
  port = 1234
)
````

You sometimes also need to provide a login and password. In general, the owner of the database will provide necessary details.


### Exercise 10

Now let's use SQL to select specific variables from the database. Run this code.

```{r connecting-to-a-database-10, exercise = TRUE}
my_sql <- "
  SELECT carat, cut, clarity, color, price 
  FROM diamonds 
  WHERE price > 15000
"
```

```{r connecting-to-a-database-10-test, include = FALSE}
my_sql <- "
  SELECT carat, cut, clarity, color, price 
  FROM diamonds 
  WHERE price > 15000
"
```

### 

This SQL code selects 5 specific variables, from the `diamonds` dataset, and then filters the rows to only keep those with `price > 15000`.

[*SQL for Data Scientists*](https://sqlfordatascientists.com/) by Renée M. P. Teate is an introduction to SQL designed specifically for the needs of data scientists, and includes examples of the sort of highly interconnected data you’re likely to encounter in real organizations.

### Exercise 11

`dbGetQuery()` is a function which takes a connection and an SQL query as a text string as inputs. It returns the result of that query as a data frame. 

Type `as_tibble()`. Within `as_tibble()`, add `dbGetQuery()` with the arguments `con` and `mpg_sql`

```{r connecting-to-a-database-11, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)


```

```{r connecting-to-a-database-11-hint-1, eval = FALSE}
...

dbGetQuery(..., ...)
```

```{r connecting-to-a-database-11-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)

dbGetQuery(con, my_sql)

dbDisconnect(con, shutdown=TRUE)
```

### 

If you’ve never seen SQL before, don’t worry! You’ll learn more about it shortly. But if you read it carefully, you might guess that it selects five columns of the diamonds dataset and all the rows where price is greater than 15,000.

### Exercise 12

The last Exercise returned a data frame, which is always annoying, especially when there are a lot of rows, as in this case. Reuse the code, but pipe the result from `dbQuery()` into `as_tibble()`.

```{r connecting-to-a-database-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r connecting-to-a-database-12-hint-1, eval = FALSE}
...

dbGetQuery(con, my_sql) |> 
  ...()
```

```{r connecting-to-a-database-12-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)

dbGetQuery(con, my_sql) |> 
  as_tibble()

dbDisconnect(con, shutdown=TRUE)
```

### 

[*Practical SQL*](https://www.practicalsql.com/) by Anthony DeBarros is written from the perspective of a data journalist (a data scientist specialized in telling compelling stories) and goes into more detail about getting your data into a database and running your own DBMS.


## dbplyr basics
### 

Now that we’ve connected to a database and loaded up some data, we can start to learn about **dbplyr**. **dbplyr** is a **dplyr** backend, which means that you keep writing **dplyr** code but the backend executes it differently. In this, **dbplyr** translates to SQL; other backends include **dtplyr** which translates to **data.table**, and **multidplyr** which executes your code on multiple cores.

### Exercise 1

Run `tbl()` on the two arguments: `con` and `"diamonds"`.

```{r dbplyr-basics-1, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)


```

```{r dbplyr-basics-1-hint-1, eval = FALSE}
...

tbl(..., ...)
```

```{r dbplyr-basics-1-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
tbl(con, "diamonds")


dbDisconnect(con, shutdown=TRUE)
```

### 

`tbl()` is a function **dtplyr** which creates a table. Note that a table is not the same thing as a tibble. Note the message at the top:

````
Source:   table<diamonds> [?? x 10]
Database: DuckDB v0.10.0 [root@Darwin 23.4.0:R 4.3.2/:memory:]
````

Your "Database" information will probably be different.


### Exercise 2

Assign the result of your call to `tbl()` to an object called `diamonds_db`.

```{r dbplyr-basics-2, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)


```

```{r dbplyr-basics-2-hint-1, eval = FALSE}
...

... <- tbl(con, "diamonds")
```

```{r dbplyr-basics-2-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
diamonds_db <- tbl(con, "diamonds")


dbDisconnect(con, shutdown=TRUE)
```

### 

There are two other common ways to interact with a database. First, many corporate databases are very large so you need some hierarchy to keep all the tables organized. In that case you might need to supply a schema, or a catalog and a schema, in order to pick the table you’re interested in:

```
diamonds_db <- tbl(con, in_schema("sales", "diamonds"))
diamonds_db <- tbl(con, in_catalog("north_america", "sales", "diamonds"))
```

Other times you might want to use your own SQL query as a starting point:

```
diamonds_db <- tbl(con, sql("SELECT * FROM diamonds"))
```

### Exercise 3

This object is lazy; when you use dplyr verbs on it, dplyr doesn’t do any work: it just records the sequence of operations that you want to perform and only performs them when needed. For example, skip a line and pipe `diamonds_db` to `filter(price > 15000)` and `select(carat:clarity, price)`.

```{r dbplyr-basics-3, exercise = TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
diamonds_db <- tbl(con, "diamonds")

```

```{r dbplyr-basics-3-hint-1, eval = FALSE}
...

diamonds_db |> 
  ...(price > 15000) |> 
  select(carat:clarity, ...)
```

```{r dbplyr-basics-3-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
diamonds_db <- tbl(con, "diamonds")

diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price)

dbDisconnect(con, shutdown=TRUE)
```

### 

You can tell this object represents a database query because it prints the DBMS name at the top, and while it tells you the number of columns, it typically doesn’t know the number of rows. This is because finding the total number of rows usually requires executing the complete query, something we’re trying to avoid.

### Exercise 4

Using the code from the previous Exercise, extend the pipe by adding `show_query()`.

```{r dbplyr-basics-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r dbplyr-basics-4-hint-1, eval = FALSE}
...

diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price) |> 
  ...
```

```{r dbplyr-basics-4-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
diamonds_db <- tbl(con, "diamonds")

diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price) |> 
  show_query()

dbDisconnect(con, shutdown=TRUE)
```

### 

You can see the SQL code generated by the **dplyr** function `show_query()`. If you know **dplyr**, this is a great way to learn SQL! Write some **dplyr** code, get **dbplyr** to translate it to SQL, and then try to figure out how the two languages match up.

### Exercise 5

To get all the data back into R, you call `collect()`. Behind the scenes, this generates the SQL, calls `dbGetQuery()` to get the data, then turns the result into a tibble.

Using the code from the previous Exercise, extend the pipe by adding `collect()`.

```{r dbplyr-basics-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r dbplyr-basics-5-hint-1, eval = FALSE}
...

diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price) |> 
  show_query() |> 
  ...
```

```{r dbplyr-basics-5-test, include = FALSE}
con <- DBI::dbConnect(duckdb::duckdb())
dbWriteTable(con, "diamonds", ggplot2::diamonds)
diamonds_db <- tbl(con, "diamonds")

diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price) |> 
  show_query() |> 
  collect()

dbDisconnect(con, shutdown=TRUE)
```

### 

Typically, you’ll use **dbplyr** to select the data you want from the database, performing basic filtering and aggregation using the translations described below. Then, once you’re ready to analyse the data with functions that are unique to R, you’ll `collect()` the data to get an in-memory tibble, and continue your work with pure R code.


## SQL
### 

The rest of the chapter will teach you a little SQL through the lens of **dbplyr**. It’s a rather non-traditional introduction to SQL but we hope it will get you quickly up to speed with the basics. Luckily, if you understand **dplyr** you’re in a great place to quickly pick up SQL because so many of the concepts are the same.


### Exercise 1

Type `con_nyc`. Hit "Run Code".

```{r sql-1, exercise = TRUE}

```

```{r sql-1-hint-1, eval = FALSE}
con_nyc
```

```{r sql-1-test, include = FALSE}
con_nyc
```

### 

In the background, we have already run this code:

```
con_nyc <- DBI::dbConnect(duckdb::duckdb())
dbplyr::copy_nycflights13(con_nyc)
```

This code is why the tutorial took so long to create. `con_nyc` is a connection, just like the ones we have created before. `copy_nycflights13()` is a utility function which transforms some of the *tibbles* from the **nycflights** package into *tables* in the duckdb we have just created.

### Exercise 2

We’ll explore the relationship between dplyr and SQL using a couple of old friends from the **nycflights13** package: flights and planes. Run `dbListTables()` on `con_nyc`. 

```{r sql-2, exercise = TRUE}

```

```{r sql-2-hint-1, eval = FALSE}
dbListTables(...)
```

```{r sql-2-test, include = FALSE}
dbListTables(con_nyc)
```

### 

### Exercise 3

Type `flights_db` set it to `tbl()`. Within `tbl()` use the `con`, `"flights"` arguments. On the next line type `planes_db` and set it to `tbl()`. Within `tbl()` use the `con` and `"planes"` arguments.

```{r sql-3, exercise = TRUE}

```

```{r sql-3-hint-1, eval = FALSE}
flights_db <- tbl(..., ...)
... <- ...(con, "planes")
```

### 

Again, these objects are not regular tibbles. They with tables (R class `tbl`) connections to the specified table in our diuckdb database.



## Function Translations
### 

This section of the chapter is too difficult to capture within the structure of a tutorial.


## Cleaning Up
### 

This section cleans up the databases, with which you were working above, from your system.

### Exercise 1

Our first step is to disconnect the database that we have created. Run the following code chunk below.

```{r cleaning-up-1, exercise = TRUE}
dbDisconnect(con, shutdown = TRUE)
```

### Exercise 2

Finally let's remove the `myDB.sqlite` from your computer. Find the location on your computer where the r4ds.tutorial is stored. Add that location to the beginning of the following code below and run the code chunk. 

```{r cleaning-up-2, exercise = TRUE}
file.remove("myDB.sqlite")
```

## Summary
### 

This tutorial covered [Chapter 21: Databases](https://r4ds.hadley.nz/databases.html) from [*R for Data Science (2e)*](https://r4ds.hadley.nz/) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. You learned how to use [**DBI**](https://dbi.r-dbi.org/) and used the [**dbplyr**](https://dbplyr.tidyverse.org/) packages to connect to databases and execute SQL. 

<!-- DK: Replace these books with free and/or open-source options. -->

For further reading consider [**Writing SQL with dbplyr**](https://dbplyr.tidyverse.org/articles/sql.html), [**Practical SQL: A Beginner's Guide to Storytelling with Data**](https://www.practicalsql.com/), and [**SQL For Data Scientists**](https://sqlfordatascientists.com/).


```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
